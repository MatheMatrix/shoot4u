From a2c33d10bbc5b6d75933aadb45d02b0d372844ab Mon Sep 17 00:00:00 2001
From: Jiannan Ouyang <jiannan.ouyang@gmail.com>
Date: Fri, 17 Jul 2015 15:27:55 -0400
Subject: [PATCH 2/2] guest support

---
 arch/x86/Kconfig                |  6 ++++++
 arch/x86/include/asm/tlbflush.h | 11 +++++++++++
 arch/x86/kernel/kvm.c           |  4 ++++
 arch/x86/mm/tlb.c               | 22 ++++++++++++++++++++++
 4 files changed, 43 insertions(+)

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index d24887b..e242188 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -588,6 +588,12 @@ config PARAVIRT_SPINLOCKS
 
 	  If you are unsure how to answer this question, answer Y.
 
+config SHOOT4U
+	bool "Paravirt TLB shoot down"
+	depends on PARAVIRT && SMP
+	---help---
+	  If you are unsure how to answer this question, answer N.
+
 source "arch/x86/xen/Kconfig"
 
 config KVM_GUEST
diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h
index 04905bf..d5b7c60 100644
--- a/arch/x86/include/asm/tlbflush.h
+++ b/arch/x86/include/asm/tlbflush.h
@@ -140,6 +140,13 @@ static inline void flush_tlb_mm_range(struct mm_struct *mm,
 		__flush_tlb_up();
 }
 
+static inline void shoot4u_flush_tlb_others(const struct cpumask *cpumask,
+					   struct mm_struct *mm,
+					   unsigned long start,
+					   unsigned long end)
+{
+}
+
 static inline void native_flush_tlb_others(const struct cpumask *cpumask,
 					   struct mm_struct *mm,
 					   unsigned long start,
@@ -177,6 +184,10 @@ extern void flush_tlb_kernel_range(unsigned long start, unsigned long end);
 
 #define flush_tlb()	flush_tlb_current_task()
 
+void shoot4u_flush_tlb_others(const struct cpumask *cpumask,
+				struct mm_struct *mm,
+				unsigned long start, unsigned long end);
+
 void native_flush_tlb_others(const struct cpumask *cpumask,
 				struct mm_struct *mm,
 				unsigned long start, unsigned long end);
diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c
index 3dd8e2c..165eec9 100644
--- a/arch/x86/kernel/kvm.c
+++ b/arch/x86/kernel/kvm.c
@@ -287,6 +287,10 @@ static void __init paravirt_ops_setup(void)
 	if (kvm_para_has_feature(KVM_FEATURE_NOP_IO_DELAY))
 		pv_cpu_ops.io_delay = kvm_io_delay;
 
+#ifdef CONFIG_SHOOT4U
+        pv_mmu_ops.flush_tlb_others = shoot4u_flush_tlb_others;
+#endif
+
 #ifdef CONFIG_X86_IO_APIC
 	no_timer_check = 1;
 #endif
diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c
index dd8dda1..30d730f 100644
--- a/arch/x86/mm/tlb.c
+++ b/arch/x86/mm/tlb.c
@@ -12,7 +12,9 @@
 #include <asm/cache.h>
 #include <asm/apic.h>
 #include <asm/uv/uv.h>
+#include <asm/bitops.h>
 #include <linux/debugfs.h>
+#include <linux/kvm_para.h>
 
 DEFINE_PER_CPU_SHARED_ALIGNED(struct tlb_state, cpu_tlbstate)
 			= { &init_mm, 0, };
@@ -122,6 +124,26 @@ static void flush_tlb_func(void *info)
 
 }
 
+void shoot4u_flush_tlb_others(const struct cpumask *cpumask,
+				 struct mm_struct *mm, unsigned long start,
+				 unsigned long end)
+{
+        // shoot4u currently uses a 8 bytes bitmap to pass target cores
+        // thus it supports up to 64 physical cores
+        u64 cpu_bitmap = 0;
+        int cpu;
+
+        for_each_cpu(cpu, cpumask) {
+          if (cpu >= 64) {
+            panic("[shoot4u] ERROR: do not support more than 64 cores\n");
+          }
+          set_bit(cpu, (void *)&cpu_bitmap);
+        }
+
+        //printk("[shoot4u] before KVM_HC_SHOOT4U hypercall, cpumask: %llx, start %lx, end %lx\n", cpu_bitmap, start, end);
+        kvm_hypercall3(KVM_HC_SHOOT4U, cpu_bitmap, start, end);
+}
+
 void native_flush_tlb_others(const struct cpumask *cpumask,
 				 struct mm_struct *mm, unsigned long start,
 				 unsigned long end)
-- 
1.8.3.1

